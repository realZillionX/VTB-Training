# VTB-Training

**VideoThinkBench å¯å¤ç°è®­ç»ƒä»£ç åº“**

ä½¿ç”¨ VideoThinkBench æä¾›çš„è®­ç»ƒé›†ï¼Œå¯¹ä¸‰ç±»æ¨¡å‹è¿›è¡Œåè®­ç»ƒï¼š
- **VLM (Qwen3-VL)**: SFT + GRPO å¼ºåŒ–å­¦ä¹ 
- **å›¾åƒç¼–è¾‘æ¨¡å‹ (Qwen-Image)**: LoRA SFT
- **è§†é¢‘ç”Ÿæˆæ¨¡å‹ (Wan2.2)**: LoRA SFT

> **æœ€æ–°çŠ¶æ€**: æœ¬é¡¹ç›®ç›®å‰çš„ç­–ç•¥æ˜¯ **Visual Centric First**ï¼Œä¼˜å…ˆéªŒè¯ Visual Reasoning ä»»åŠ¡ã€‚è¯¦æƒ…è§ä¸‹æ–¹ "Project Status" ç« èŠ‚ã€‚

## ç¯å¢ƒè¦æ±‚

- Python 3.10+
- CUDA 12.0+
- **VLM è®­ç»ƒ**: `ms-swift`, `peft`, `vllm`
- **å›¾åƒ/è§†é¢‘è®­ç»ƒ**: `DiffSynth-Studio`, `accelerate`, `deepspeed`

```bash
pip install -r requirements.txt
```

## å¿«é€Ÿå¼€å§‹

### 1. VLM è®­ç»ƒ (Qwen3-VL)

```bash
# å‡†å¤‡æ•°æ®ï¼ˆæ”¯æŒç›´æ¥è¯»å– VLMPuzzle çš„ data.jsonï¼‰
python -m data.tools.prepare_vlm_data \
    --data_root /path/to/VLMPuzzle/dataset \
    --output_dir ./dataset

# SFT è®­ç»ƒ
cd training/vlm && bash train_sft.sh --model_path /path/to/Qwen3-VL-32B

# GRPO å¼ºåŒ–å­¦ä¹ 
python train_grpo.py --model_path /path/to/sft_checkpoint
```

### 2. å›¾åƒç¼–è¾‘æ¨¡å‹è®­ç»ƒ (Qwen-Image)

```bash
# å‡†å¤‡æ•°æ®
python -m data.tools.prepare_image_data \
    --dataset_root /path/to/VLMPuzzle/dataset \
    --output_path ./dataset/metadata.json

# è®­ç»ƒ
cd training/image
DIFFSYNTH_PATH=/path/to/DiffSynth-Studio bash train_sft.sh
```

### 3. è§†é¢‘ç”Ÿæˆæ¨¡å‹è®­ç»ƒ (Wan2.2)

```bash
# æ•°æ®å‡†å¤‡ï¼ˆç”Ÿæˆ CSVï¼‰
python -m data.tools.prepare_video_data \
    --dataset_root /path/to/VLMPuzzle/dataset \
    --output_path ./dataset/train_video.csv

# ç»Ÿä¸€è®­ç»ƒè„šæœ¬ï¼ˆå•æœº / å¤šæœºï¼‰
cd training/video
MODEL_BASE_PATH=/path/to/Wan2.2-TI2V-5B \
DIFFSYNTH_PATH=/path/to/DiffSynth-Studio \
bash train_sft.sh --dataset ./dataset/train_video.csv --num_nodes 1
```

---

## Project Status & Plan

> **æ ¸å¿ƒåŸåˆ™**: Video Generation Reasoning çš„æ¢ç´¢ç›®å‰ä¼˜å…ˆé‡‡ç”¨ **Visual Centric First** å’Œ **Single-Task Training** è·¯å¾„ã€‚

### 1. è®­ç»ƒæ•°æ®çŠ¶æ€ (Training Data Status)

Visual Centric ä»»åŠ¡çš„ç”Ÿæˆå™¨ä»£ç å¤§å¤š**å·²å­˜åœ¨**ï¼ˆ`data/puzzle/`ï¼‰ï¼Œä¸»è¦ Gap åœ¨äº**è®­ç»ƒæ•°æ®çš„ç”Ÿæˆé…ç½®**ã€‚

| ä»»åŠ¡ç±»å‹ | å­ä»»åŠ¡ | ä»£ç çŠ¶æ€ | è®­ç»ƒæ•°æ®é…ç½®çŠ¶æ€ |
| :--- | :--- | :--- | :--- |
| **Maze** | **Square Maze** | âœ… Ready | âœ… **Finalized**: å·²éªŒè¯ã€‚é…ç½®ä¸º 7Ã—7, 9Ã—9, 11Ã—11 ä¸‰ç§å°ºå¯¸ï¼Œå•æ–¹å— 32pxï¼Œå„ç”Ÿæˆ 10k ç»„ã€‚ |
| | Hexagon Maze | âœ… Ready | ğŸš§ **Pending**: ä»£ç å°±ç»ªï¼Œå¯ä»¥å°†è¾¹é•¿/åƒç´ å¤§å°ä½œä¸ºå‚æ•°æš´éœ²ï¼Œå¾…ç¡®å®šæœ€ä½³è®­ç»ƒå‚æ•°ã€‚ |
| | Circle Maze | âœ… Ready | ğŸš§ **Pending**: åŒä¸Šï¼Œéœ€è°ƒè¯•ç”Ÿæˆå‚æ•°ã€‚ |
| **Eyeballing** | å…¨é‡ 21 ç±» | âœ… Ready | ğŸš§ **Pending**: ä»£ç å°±ç»ªã€‚éœ€ç¼–å†™æ‰¹é‡ç”Ÿæˆè„šæœ¬ï¼Œå¹¶å°†éš¾åº¦/è§†è§‰å‚æ•°ï¼ˆå¦‚çº¿æ¡ç²—ç»†ã€ç‚¹å¤§å°ï¼‰å‚æ•°åŒ–ï¼Œä»¥ä¾¿ç”Ÿæˆå¤šæ ·åŒ–æ•°æ®ã€‚ |
| **Visual Puzzles** | Color/Shape | âœ… Ready | â¸ï¸ **Deferred**: æš‚ä¸ä½œä¸ºè®­ç»ƒé‡ç‚¹ã€‚ |
| **ARC-AGI-2** | Abstract | âœ… Ready | â¸ï¸ **Deferred**: æš‚ä¸ä½œä¸ºè®­ç»ƒé‡ç‚¹ã€‚ |

### 2. å¾…åŠäº‹é¡¹ (TODO List)

#### Phase 1: ä»£ç åº“é‡æ„ - âœ… DONE
- [x] **ç›®å½•ç»“æ„æ•´ç†**: å®Œæˆ `eyeballing`, `maze`, `visual` çš„åˆ†ç±»æ•´ç†ã€‚
- [x] **Import ä¿®å¤**: ä¿®æ­£äº†é‡æ„å¸¦æ¥çš„ç›¸å¯¹è·¯å¾„å¼•ç”¨é—®é¢˜ã€‚

#### Phase 2: æ ¸å¿ƒä»»åŠ¡æ•°æ®ç”Ÿæˆ (Data Generation)
- [x] **Eyeballing (High Priority)**: ç¼–å†™ `generate_eyeballing_video.py`ï¼Œæ”¯æŒ CLI å‚æ•°é…ç½®éš¾åº¦/ç”»å¸ƒå°ºå¯¸ã€‚
- [x] **Maze**: ç¼–å†™ Hexagon/Circle çš„å‚æ•°åŒ–ç”Ÿæˆè„šæœ¬ã€‚

#### Phase 3: æ¨¡å‹è®­ç»ƒ (Training)
- [ ] **Wan2.2 Single-Task**: å¾… Eyeballing æ•°æ®ç”Ÿæˆåï¼Œå¯åŠ¨å•ä»»åŠ¡è®­ç»ƒã€‚
- [ ] **VLM / Image Model**: åŒæ­¥å¯åŠ¨ SFTã€‚

## é¡¹ç›®ç»“æ„

```
VTB-Training/
â”œâ”€â”€ data/                      # æ ¸å¿ƒåº“ (Python Package)
â”‚   â”œâ”€â”€ puzzle/                # Generator æºç  (Maze, Eyeballing)
â”‚   â”œâ”€â”€ tools/                 # æ‰¹é‡æ•°æ®ç”Ÿæˆå·¥å…·
â”‚   â””â”€â”€ utils/                 # é€šç”¨å·¥å…·
â”œâ”€â”€ dataset/                   # æ•°æ®äº§ç‰© (å·²å¿½ç•¥)
â”œâ”€â”€ training/                  # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ vlm/                   # Qwen3-VL
â”‚   â”œâ”€â”€ image/                 # Qwen-Image
â”‚   â””â”€â”€ video/                 # Wan2.2
â”œâ”€â”€ code_test/                 # æ—§ç‰ˆå•å…ƒæµ‹è¯•ï¼ˆå»ºè®®é€æ­¥è¿ç§»åˆ° tests/ï¼‰
â””â”€â”€ tests/                     # è¯„æµ‹è„šæœ¬ä¸è½»é‡å•æµ‹ï¼ˆå« evaluator/vlm/video/image å››ä¸ªåˆ†åŒºï¼‰
```

## å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨äº†æœ¬ä»£ç åº“ï¼Œè¯·å¼•ç”¨ "Thinking with Video" è®ºæ–‡ï¼š

```bibtex
@article{tong2025thinking,
  title={Thinking with video: Video generation as a promising multimodal reasoning paradigm},
  author={Tong, Jingqi and Mou, Yurong and Li, Hangcheng and Li, Mingzhe and Yang, Yongzhuo and Zhang, Ming and Chen, Qiguang and Liang, Tianyi and Hu, Xiaomeng and Zheng, Yining and others},
  journal={arXiv preprint arXiv:2511.04570},
  year={2025}
}
```

## è®¸å¯è¯

MIT License
